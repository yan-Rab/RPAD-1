# RPAD-1
# ğŸ· PCA + KMeans: Agrupamento no Dataset de Vinhos

> Projeto em Python que aplica **AnÃ¡lise de Componentes Principais (PCA)** e **K-Means Clustering** no clÃ¡ssico dataset de vinhos do `scikit-learn`, com visualizaÃ§Ã£o e avaliaÃ§Ã£o dos resultados.

---

## ğŸ“˜ Sobre o Projeto

Este projeto demonstra como reduzir a dimensionalidade de um conjunto de dados real usando **PCA (Principal Component Analysis)** e, em seguida, aplicar **K-Means** para identificar grupos semelhantes â€” tudo isso **sem usar os rÃ³tulos verdadeiros**.

O dataset utilizado Ã© o [`load_wine`](https://scikit-learn.org/stable/datasets/toy_dataset.html#wine-dataset) do `scikit-learn`, que contÃ©m **178 amostras de vinhos** com **13 atributos quÃ­micos** (como teor alcoÃ³lico, acidez, magnÃ©sio, flavonÃ³ides, etc.) divididos em **3 classes de cultivares**.

---

## ğŸ§  Conceitos Principais

### ğŸ§© PCA (Principal Component Analysis)
- Reduz a dimensionalidade dos dados mantendo a **maior variÃ¢ncia possÃ­vel**.
- Cada **componente principal** Ã© uma combinaÃ§Ã£o linear das variÃ¡veis originais.
- No projeto, usamos **2 componentes** para visualizar os dados em 2D.

FÃ³rmula bÃ¡sica da projeÃ§Ã£o:
\[
Z = X \cdot W
\]
onde:
- \(X\): dados originais padronizados  
- \(W\): autovetores (componentes principais)  

---

### âš™ï¸ K-Means Clustering
- Algoritmo **nÃ£o supervisionado** que agrupa amostras em \(K\) grupos com base na proximidade.
- Define **centroides** que representam cada cluster.
- Cada ponto Ã© atribuÃ­do ao **centrÃ³ide mais prÃ³ximo** (menor distÃ¢ncia Euclidiana).

Etapas do K-Means:
1. Inicializa \(K\) centroides aleatoriamente  
2. Atribui cada ponto ao centrÃ³ide mais prÃ³ximo  
3. Atualiza os centroides como a mÃ©dia dos pontos de cada cluster  
4. Repete atÃ© convergir

---

## ğŸ§ª Etapas do CÃ³digo

| Etapa | DescriÃ§Ã£o |
|:------|:-----------|
| **1. Carregamento dos Dados** | Usa `load_wine()` para obter `X` (atributos) e `y` (classes reais). |
| **2. PadronizaÃ§Ã£o (`StandardScaler`)** | Normaliza os dados para mÃ©dia 0 e desvio 1, essencial para o PCA. |
| **3. ReduÃ§Ã£o de Dimensionalidade (`PCA`)** | Reduz as 13 features para 2 componentes principais. |
| **4. Agrupamento (`KMeans`)** | Agrupa os dados em 3 clusters (pois sabemos que hÃ¡ 3 tipos de vinho). |
| **5. Mapeamento de Clusters â†’ Classes** | Ajusta as cores para que os clusters correspondam Ã s classes reais. |
| **6. VisualizaÃ§Ã£o** | Plota dois grÃ¡ficos lado a lado: classes reais vs clusters descobertos. |

---

## ğŸ“Š VisualizaÃ§Ã£o

| Classes Reais | Clusters (KMeans) |
|----------------|------------------|
| ![classes](https://user-images.githubusercontent.com/your-example-link-left.png) | ![clusters](https://user-images.githubusercontent.com/your-example-link-right.png) |

> ğŸ”¹ As cores do grÃ¡fico de KMeans sÃ£o ajustadas para coincidir com as classes reais.  
> ğŸ”¸ Os **X vermelhos** representam os **centroides** descobertos pelo algoritmo.

---

## ğŸ§® MÃ©tricas

Durante a execuÃ§Ã£o, sÃ£o exibidos:

- **VariÃ¢ncia explicada pelo PCA** â†’ Ex: `0.55` (55%)  
- **Matriz de confusÃ£o** entre classes reais e clusters  
- **AcurÃ¡cia aproximada** apÃ³s mapeamento de clusters â†’ Ex: `~0.90`

---

## ğŸ§° Requisitos

| Biblioteca | DescriÃ§Ã£o |
|-------------|------------|
| `scikit-learn` | Machine learning e datasets |
| `matplotlib` | VisualizaÃ§Ã£o dos grÃ¡ficos |
| `numpy` | OperaÃ§Ãµes numÃ©ricas |
| `pandas` | ManipulaÃ§Ã£o de dados |

InstalaÃ§Ã£o:

```bash
pip install scikit-learn matplotlib numpy pandas
